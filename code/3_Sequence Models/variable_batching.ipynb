{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from urllib import request\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import LongTensor\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Embedding\n",
    "from torch.nn.utils.rnn import pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget, os, gzip, pickle, random, re, sys\n",
    "\n",
    "IMDB_URL = ## removed (internal)\n",
    "IMDB_FILE = ## removed (internal)\n",
    "\n",
    "PAD, START, END, UNK = '.pad', '.start', '.end', '.unk'\n",
    "\n",
    "def load_imdb(final=False, val=5000, seed=0, voc=None, char=False):\n",
    "\n",
    "    cst = 'char' if char else 'word'\n",
    "\n",
    "    imdb_url = IMDB_URL.format(cst)\n",
    "    imdb_file = IMDB_FILE.format(cst)\n",
    "\n",
    "    if not os.path.exists(imdb_file):\n",
    "        wget.download(imdb_url)\n",
    "\n",
    "    with gzip.open(imdb_file) as file:\n",
    "        sequences, labels, i2w, w2i = pickle.load(file)\n",
    "\n",
    "    #print(len(w2i))\n",
    "    #print(len(i2w))\n",
    "    if voc is not None and voc < len(i2w):\n",
    "        nw_sequences = {}\n",
    "\n",
    "        i2w = i2w[:voc]\n",
    "        w2i = {w: i for i, w in enumerate(i2w)}\n",
    "\n",
    "        mx, unk = voc, w2i['.unk']\n",
    "        for key, seqs in sequences.items():\n",
    "            nw_sequences[key] = []\n",
    "            for seq in seqs:\n",
    "                seq = [s if s < mx else unk for s in seq]\n",
    "                nw_sequences[key].append(seq)\n",
    "\n",
    "        sequences = nw_sequences\n",
    "\n",
    "    if final:\n",
    "        return (sequences['train'], labels['train']), (sequences['test'], labels['test']), (i2w, w2i), 2\n",
    "\n",
    "    # Make a validation split\n",
    "    random.seed(seed)\n",
    "\n",
    "    x_train, y_train = [], []\n",
    "    x_val, y_val = [], []\n",
    "\n",
    "    val_ind = set( random.sample(range(len(sequences['train'])), k=val) )\n",
    "    for i, (s, l) in enumerate(zip(sequences['train'], labels['train'])):\n",
    "        if i in val_ind:\n",
    "            x_val.append(s)\n",
    "            y_val.append(l)\n",
    "        else:\n",
    "            x_train.append(s)\n",
    "            y_train.append(l)\n",
    "\n",
    "    return (x_train, y_train), \\\n",
    "           (x_val, y_val), \\\n",
    "           (i2w, w2i), 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val), (i2w, w2i), numcls = load_imdb(final=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    data_list = []\n",
    "    for _data in batch:\n",
    "        data_list.extend(_data)\n",
    "       \n",
    "    one_batch = torch.tensor(data_list, dtype = torch.long)\n",
    "    return (one_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(x_train[:10], batch_size=2, shuffle=False, collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding on Sorted batches \n",
    "seq_lengths = LongTensor(list(map(len, dataloader)))\n",
    "seq_tensor = torch.zeros((len(dataloader), seq_lengths.max())).long()\n",
    "\n",
    "for idx, (seq, seqlen) in enumerate(zip(dataloader, seq_lengths)):\n",
    "    seq_tensor[idx, :seqlen] = LongTensor(seq)\n",
    "\n",
    "seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
    "seq_tensor = seq_tensor[perm_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   13,    90,    25,   123,   138,    13,    42,    14,    19,    40,\n",
      "           73,    22,    13,   116,    79,  1414,     7,   153,    11,    84,\n",
      "           19,   262,     4,   210, 52811,   598,    35,   240,    14,  2423,\n",
      "         8932,    55,    24,    31,   418,   257,    15,   310,   285])\n",
      "tensor([  14,    9,    4, 6750,   19,  320,    7, 3526, 3931, 1911,  167,   22,\n",
      "          43,   29,   60,  986,  388,    6,  664,    7,  129,   27,  889,    8,\n",
      "        2578,   89,  750, 2297,    5, 7684,   78,   14,   19,    9,    0,    0,\n",
      "           0,    0,    0])\n",
      "tensor([   60,   913,   366,    19,   118,   836,    44,   431,   902,    60,\n",
      "          286,    35,    34,  1834,    11, 15069,   398,  1415,     9,     4,\n",
      "          122,   398,     7, 15069,    11,    16,    62,   516,   398,     7,\n",
      "        15069,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "tensor([10721,     4, 10956,   129,     6,   124, 88114,     5,     6,    19,\n",
      "           93,  4118,   198,   351, 17697,   116,    31,    13,    80,    40,\n",
      "         1240,     8,    69,   272,   883,  1749,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "tensor([  14,   19,    9,  379,   22,   11,   50,   52,   53,  290,   13,  574,\n",
      "          25,  809,   14,   32,   63,   26, 2722, 2231,  312,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "for row in seq_tensor:\n",
    "    print(row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
